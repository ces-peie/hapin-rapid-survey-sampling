---
title: Sampling for HAPIN first stage - clusters
author: Oscar de Le√≥n - `r Sys.Date()`
header-includes:
- \usepackage{pdflscape}
- \newcommand{\blandscape}{\begin{landscape}}
- \newcommand{\elandscape}{\end{landscape}}
output:
  pdf_document: default
  html_document: default
---


```{r setup, echo=FALSE, message=FALSE, warning=FALSE}
# Load used packages
library(package = "raster")
library(package = "rgeos")
library(package = "maptools")
library(package = "tidyverse")

# Configure knitr
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
knitr::opts_knit$set(root.dir = "..")
```


We have considered a two stage sampling design to select households for the rapid assessment.
In this document I describe the first sampling stage,
which involves defining and randomly selecting clusters
so that every household in the study area
has the same probability of being included in the assessment.




# Define parameters

To define and randomly select clusters within the study area
it is necessaty to know the number and location of households.
Since this information is not available, I used the population density provided by WorldPop.
These data are delivered as a spatial raster with a resolution of 8.33x10^-4^ degrees
(approximately 100x100m at the equator)
containing the predicted number of inhabitants per cell.
To inform the cluster selection with these data we have to make an assumption
about the number of inhabitants per household (*i.e.* the household size),
and we also need to account for failure to include households (percent response)
and for selecting unsuitable clusters (*e.g.* clusters without enough households).
I included below the values used for these assumptions.


```{r sampling-parameters, echo=TRUE}
# Population parameters
household_size <- 6                                # people per household

# Sampling parameters
sample_size <- 400                                 # households
cluster_size <- 10                                 # households per cluster
n_clusters <- ceiling(sample_size / cluster_size)  # enough clusters for ss

# Inefficiency
response <- 2/3                                # proportion contacted included
suitable <- 1/5                                # proportion of suitable clusters
adj_clusters <- ceiling(n_clusters / suitable) # Adjusted number of clusters

```




# Administrative limits

The rapid assessment will be performed in some municipalities of the Jalapa department.
Below I show the administrative limits of Jalapa (**Fig. 1**),
the selected municipalities (**Fig. 2**),
and some areas that are to be excluded (**Fig. 3**).


```{r get-limits-data}
# Set included municipalities
included <- c(
  "Jalapa", "San Pedro Pinula", "San Carlos Alzatate", "San Luis Jilotepeque"
)

# Read in limits
municipalities <- readShapePoly(
  fn = "data/shapefiles/borders/municipalities.shp"
)

# Keep only Jalapa
jalapa <- municipalities %>%
  subset(as.character(COD_MUNI) >= 2100 & as.character(COD_MUNI) < 2200)

# Keep only study municipalities
study_munis <- jalapa %>%
  subset(MUNICIPIO %in% included)

# Get top left corner
top_left <-  study_munis %>%
  bbox %>%
  as.data.frame() %>%
  rownames_to_column(var = "direction") %>%
  gather(variable, coordinate, -direction) %>%
  group_by(direction) %>%
  slice(which.max(abs(coordinate))) %>%
  select(direction, coordinate) %>%
  spread(direction, coordinate) %>%
  set_names(toupper(names(.)))

# Read exluded areas
excluded_communities <- "./data/jalapa-excluded-communities.csv" %>%
  # Get the list
  read_csv() %>%
  filter(
    !NUEVO_COD %in% c(2101222, 2101047)
  ) %>%
  # Extend west and north
  bind_rows(
    .,
    top_left,
    mutate(top_left, Y = min(.$Y))
  ) %>%
  # Convert to spatial object
  SpatialPointsDataFrame(
    coords = select(., long = X, lat = Y),
    # coords.nrs = 1:2,
    data = .,
    proj4string = CRS("+init=epsg:4326")
  )

# Get Jalapa "metro" area to exclude it
jalapa_metro <- readShapePoly(
  "./data/shapefiles/community_outlines/Poligonos lugares poblados.shp"
) %>%
  subset(NAME == "JALAPA")

# Get the convex hull containing the excluded comunities and Jalapa "metro"
excluded_hull <- excluded_communities %>%
  gConvexHull() %>%
  # Join with Jalapa "metro" area
  gUnion(jalapa_metro) %>%
  # Intersect with study municipalities
  gIntersection(study_munis)

# Subtract excluded areas
study_area <- gDifference(study_munis, excluded_hull)
```


```{r geo-limits, results='hold', out.width="0.33\\linewidth"}
# Base political limits
plot(jalapa)
title("Fig. 1: Jalapa municipalities")
text(
  coordinates(jalapa),
  labels = gsub(
    pattern = " ",
    replacement = "\n",
    x = iconv(
      x = as.character(jalapa$MUNICIPIO),
      from = "Latin1",
      to = "ASCII//TRANSLIT"
    )
  ),
  cex=0.6
)

# Selected municipalities
plot(jalapa, col = "grey90")
plot(study_munis, col = "white", add = TRUE)
title("Fig. 2: Municipalities included in study")
text(
  coordinates(study_munis),
  labels = gsub(
    pattern = " ",
    replacement = "\n",
    x = iconv(
      x = as.character(study_munis$MUNICIPIO),
      from = "Latin1",
      to = "ASCII//TRANSLIT"
    )
  ),
  cex=0.6
)

# Excluded areas
plot(jalapa, col = "grey90")
plot(study_munis, col = "white", add = TRUE)
plot(excluded_hull, col = "grey40", add = TRUE)
title("Fig. 3: Excluded areas")
text(
  coordinates(study_munis) - matrix(c(0, -0.02, 0, 0, 0, 0.05, 0, 0), ncol = 2),
  labels = gsub(
    pattern = " ",
    replacement = "\n",
    x = iconv(
      x = as.character(study_munis$MUNICIPIO),
      from = "Latin1",
      to = "ASCII//TRANSLIT"
    )
  ),
  cex=0.6
)
```




# Population density


```{r get-density-data}

# Read in rasters
pop_density <- raster(x = "data/jalapa_density.gri")

# Limit to study area
study_density <- rasterize(study_area, pop_density, mask = TRUE)

# Median cell density
median_density <- median(study_density[], na.rm = TRUE)

# Minimum cluster (area) population for household_size
min_cluster_pop <- household_size * (cluster_size / response)

# Inflate cluster size to ensure enough households
adj_cluster_pop <- min_cluster_pop * 2 / median_density

# Calculate cells per (square) cluster
cluster_side <- ceiling(sqrt(adj_cluster_pop))

# Aggregate population cells
cluster_cells <- aggregate(study_density, fact = cluster_side, fun = sum)

# Percent with enough estimated households
cluster_ecdf <- ecdf(cluster_cells[])
percent_small <- ceiling(cluster_ecdf(cluster_size / response)*100)
```


In **Fig. 4** I show the raw population density from the WorldPop model,
masked by the excluded areas (in dark grey).
The highest population densities
(~`r round(max(study_density[], na.rm = TRUE))` persons per household, pph)
are found close to (and inside) the excluded Jalapa "metropolitan" area.
The population density is skewed to lower values
(median ~ `r round(median_density)`, **Fig. 5**),
so we have to carefully define the clusters geographical extent to improve
the probability of selecting clusters with an addequate number of households.


```{r pop-density, results='hold', out.width="0.5\\linewidth"}
# Raw density
dpar <- par()
par(mar = c(2, 2, 3, 1))
plot(study_density)
title("Fig. 4: Raw population density\nand study areas")
plot(jalapa, add = TRUE, asp = 1)
plot(excluded_hull, add = TRUE, col = "grey20", asp = 1)
lines(study_munis, col = "red")
par(dpar)

# Raw density
hist(
  study_density, maxpixels = 1e6,
  breaks = seq(0, ceiling(max(study_density[], na.rm = TRUE))),
  xlab = "Count in cells", ylab = "n",
  main = "Fig. 5: Distribution of population density values"
)
```



# Sampling clusters

We want to sample `r cluster_size` households within each cluster, and considering
a `r signif(response*100, 3)`% of response we need to have *at least*
`r ceiling(cluster_size / response)` households,
amounting to `r min_cluster_pop` individuals per cluster.
To define the geographical extent for the clusters I took into account that
50% of the ~100x100m WorldPop cells have a value smaller than `r round(median_density)`,
and adjusted the cluster population[^1] to ~`r ceiling(adj_cluster_pop)` to ensure
that most clusters have at least the number of households we want to sample.

[^1]: Adjusted the needed cluster population to twice the original size,
divided by the median density.

The resulting cluster population requires to aggregate the population density data
to square "cluster sized" cells with `sqrt(adjusted population)` ~ `r cluster_side`
raw cells per side, assuming the median density per cell.
This aggregation results in cells with a resolution of roughly `r signif(res(cluster_cells)[1], 1)`
degrees, or `r cluster_side*100`m,
with at most `r percent_small`% containing less than `r cluster_size / response` households.
I used the total population of each cluster-sized cell as weights[^2] to
randomly select `r adj_clusters` clusters with probability proportional to size, with replacement.
Since the next sampling stage involves randomly picking the same number of 
households within each cluster,
this would ideally allow for every household in the study area to have the
same probability of being selected.


[^2]: Using the value of each cell relative to the maximum value among all cells
as the probability to sample it.



```{r sample-clusters}
# Set seed for reproducibility
set.seed(2017-05)

# Half width
hs <- res(cluster_cells)/2

# Calculate weights
weights <- cluster_cells
weights[is.na(weights[])] <- 0         # set NAs to 0 for sampling
weights <- weights / max(weights[])    # scale to probabilities

# First stage of sampling: sample clusters
sampled_clusters <- sample(
  x = seq_len(length.out = length(weights[])),
  size = adj_clusters,
  replace = TRUE,
  prob = weights[]
)

# Get locations of sample clusters
centers <- xyFromCell(cluster_cells, sampled_clusters)

# Get polygons for each cluster
cluster_cells[is.na(cluster_cells)] <- 0
cluster_polygons <- rasterToPolygons(
  x = cluster_cells
)[unique(sampled_clusters), ]


# Collect data for sample clusters
clusters <- cluster_polygons@data %>%
  rownames_to_column(var = "cell_id") %>%
  mutate(
    correlative = seq(1, n()),
    times = as.vector(table(sampled_clusters)),
    households = layer / household_size
  ) %>%
  select(correlative, cell_id, times, population = layer, households) %>%
  bind_cols(as_tibble(unique(centers))) %>%
  rename(lat = y, long = x)

# Force rownames on cluster data
rownames(clusters) <- clusters$cell_id


# Edit clusters data
cluster_polygons <- SpatialPolygonsDataFrame(
  Sr = cluster_polygons,
  data = clusters,
  match.ID = TRUE
)
```


A very common approach to spatial sampling uses *geographically balanced sampling*,
which ensures equally-sized areas are represented in the sampling
(usually through some sort of tesselation).
This is very important when there is a strong spatial effect on the dependent
variables or covariates,
but less so when no spatial associations are expected.
The method used to select the clusters in this document *does not* provide a
spatially balanced sample,
but this should not have a big impact on representativity since most of the study
area is so sparesly populated[^3].
In **Fig. 6** I show the aggregated population density and the randomly
selected clusters.


[^3]: A spatially balanced sample could prove more useful for the second sampling
stage, given that factors at a lower geographical scale
(e.g. point sources of pollution such as factories, sites with regular crop burning,
or areas with heavier motor vehicle trafic) could have a big effect on individual
households.

In **Fig. 7** I include some tiles from satellite imagery provided by Google,
representing selected clusters with low or high estimated number of households.


\newpage
\blandscape

```{r clusters-density, dpi=600, out.width="1\\linewidth", fig.width=9, fig.height=6.5}
dpar <- par()
par(mar = c(2, 2, 3, 1))
plot(cluster_cells)
title("Fig. 6: Aggregated population density and selected clusters")
plot(jalapa, add = TRUE, asp = 1)
lines(excluded_hull, col = rgb(0, 0, 1, 0.5), add = TRUE, asp = 1)
plot(cluster_polygons, add = TRUE, asp = 1)
text(
  coordinates(cluster_polygons),
  labels = cluster_polygons$correlative,
  cex = 0.4, col = "red"
)
par(dpar)
```

\elandscape



```{r write-data, cache=TRUE}
# Write cluster data
clusters %>%
    mutate(
        tipo = "",
        suficientes = "",
        comentario = ""
    ) %>%
  write_csv(path = "output/clusters.csv")

# Write cluster polygons
writeSpatialShape(cluster_polygons, fn = "output/clusters/clusters")

# Function to get cluster tiles
get_tile <- function(cluster, save_path, zoom = 16){
  # file path
  save_path <- file.path(
    save_path,
    stringr::str_pad(
      string = cluster$correlative, width = 2, side = "left", pad = "0"
    )
  )
  
  if(!file.exists(paste0(save_path, ".tif"))){
    # cell center
    center <- cluster[c("lat", "long")] %>% unlist()
    
    # Get tile
    cell <- RgoogleMaps::GetMap(
      center = center[c("lat", "long")], zoom=16, maptype = "satellite"
    )
    
    # Convert to raster
    bb <- cell$BBOX
    cell <- stack(file.path(tempdir(), "mapTile.png"))
    extent(cell) <- extent(bb$ll[,2],bb$ur[,2],bb$ll[,1],bb$ur[,1])
    
    # Save as GTiff
    writeRaster(
      x = cell, filename = save_path, format = "GTiff", overwrite = TRUE
    )
    # Copy the downloaded png
    file.copy(file.path(tempdir(), "mapTile.png"), paste0(save_path, ".png"))
    
  }
  
  cell <- brick(paste0(save_path, ".tif"))
  
  return(cell)
}

# Get all cells
clusters <- clusters %>%
  group_by(correlative, population, households, lat, long) %>%
  do(
    cell = get_tile(cluster = ., save_path = "output/cluster_satellite")
  ) %>%
  ungroup()
```


# Cluster evaluation

```{r cluster-suitability, include=FALSE}
# Load visual assessment data
jrivera <- read_csv("data/roofs/cluster_rapid_jrivera.csv")
aramirez <- read_excel("data/roofs/cluster_rapid_aramirez.xlsx")


# Standardize input
st_jrivera <- jrivera %>%
  select(
    correlative, cell_id,
    jr_type = tipo, jr_assesment = suficientes, jr_comment = comentario
  ) %>%
  mutate(
    jr_type = case_when(
      grepl("Rural", jr_type, ignore.case = TRUE) ~ "rural",
      grepl("Urb", jr_type, ignore.case = TRUE) ~ "urban",
      is.na(jr_type) ~ NA_character_,
      TRUE ~ "error"
    )
  )

st_aramirez <- aramirez %>%
  select(
    correlative, cell_id,
    ar_type = tipo, ar_assesment = suficientes, ar_comment = comentario
  ) %>%
  mutate(
    ar_type = case_when(
      grepl("R", ar_type, ignore.case = TRUE) ~ "rural",
      grepl("U", ar_type, ignore.case = TRUE) ~ "urban",
      is.na(ar_type) ~ NA_character_,
      TRUE ~ "error"
    )
  )




#------------------------------------------------------------------------------*
# Review assessment
#------------------------------------------------------------------------------*

# Join assessments
assessment <- st_aramirez %>%
  left_join(st_jrivera)


# Compare assesment

# Evaluated by jrivera
assessment %>% filter(jr_type %in% c("urban", "rural")) %>% nrow()

# Evaluated by aramirez
assessment %>% filter(ar_type %in% c("urban", "rural")) %>% nrow()

# Concordance among evaluated
assessment %>% filter(!is.na(jr_type)) %>% count(ar_type, jr_type)

# Review discordances in cluster type (rural vs urban)
assessment %>%
  filter(
    !is.na(jr_type),
    jr_type != ar_type
  )

# Review discordances in cluster suitability
assessment %>%
  filter(
    !is.na(jr_type),
    jr_assesment != ar_assesment,
    # Remove cluster 60 (cell id 1127)
    correlative != 60
  ) %>%
  select(-ar_comment, -jr_comment)


# Get list of clusters evaluated as suitable
suitable <- assessment %>%
  filter(
    ar_assesment == 1,
    correlative != 57
  )

```


All randomly selected clusters were evaluated by two independent reviewers to
assess if they were suitable for inclusion in the scoping survey.
This was done by looking at recent satellite imagery for each cluster
and estimating the number of structures found in each one by counting the visible roofs.
Clusters were deemed suitable if at least 20 roofs were observed by the reviewer.




```{r some-clusters, fig.width=6.5, fig.height=9, out.width="1\\linewidth", cache.rebuild=TRUE, dpi=600}
# Reproducible sampling
set.seed(2017-05)

# panels
panels <- c(4, 3)

# Select tiles
tiles <- clusters %>%
  group_by(households > 100) %>%
  sample_n(ceiling(prod(panels) / 2)) %>%
  ungroup() %>%
  arrange(desc(households)) %>%
  slice(1:prod(panels)) %>%
  rownames_to_column(var = "order") %>%
  mutate(
    cluster = map(
      correlative,
      ~subset(cluster_polygons, cluster_polygons$correlative == .x)
    )
  )

# Set plot parameters
dpar <- par()
par(
  mar = c(1, 1, 1, 1), # panel margins
  mfrow = panels,     # fill 12 panels by row
  oma = c(0, 3, 4, 3)  # outer margin for overall title
)

# Plot each tile
tiles %>%
  split(.$order) %>%
  walk(
    ~{
      plotRGB(x = .x$cell[[1]])
      lines(.x$cluster[[1]], lwd = 2, lty = 2)
      mtext(
        paste0(
          "Cluster ", .x$correlative, ": ",
          floor(.x$households), " households."
        ),
        side = 3, cex = 0.8, padj = 0.9
      )
    }
  )

# Add title
title("Fig. 7: Tiles from selected clusters.", outer=TRUE)
par(dpar)
```


