---
title: Sampling for HAPIN scoping - clusters
author: Oscar de Le√≥n - `r Sys.Date()`
header-includes:
- \usepackage{pdflscape}
- \newcommand{\blandscape}{\begin{landscape}}
- \newcommand{\elandscape}{\end{landscape}}
output:
  pdf_document: default
  html_document: default
---


```{r setup, echo=FALSE, message=FALSE, warning=FALSE}
# Load used packages
library(package = "readxl")
library(package = "raster")
library(package = "rgeos")
library(package = "maptools")
library(package = "sf")
library(package = "git2r")
library(package = "tidyverse")

# Configure knitr
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
knitr::opts_knit$set(root.dir = "..")
```


We have considered a two stage sampling design to select households for the rapid assessment.
In this document I describe the first sampling stage,
which involves defining and randomly selecting clusters
so that every household in the study area
has the same probability of being included in the assessment.




# Define parameters

To define and randomly select clusters within the study area
it is necessaty to know the number and location of households.
Since this information is not available, I used the population density provided by WorldPop.
These data are delivered as a spatial raster with a resolution of 8.33x10^-4^ degrees
(approximately 100x100m at the equator)
containing the predicted number of inhabitants per cell.
To inform the cluster selection with these data we have to make an assumption
about the number of inhabitants per household (*i.e.* the household size),
and we also need to account for failure to include households (percent response)
and for selecting unsuitable clusters (*e.g.* clusters without enough households).
I included below the values used for these assumptions.


```{r sampling-parameters, echo=TRUE}
# Population parameters
household_size <- 6                                # people per household

# Sampling parameters
sample_size <- 400                                 # households
cluster_size <- 10                                 # households per cluster
n_clusters <- ceiling(sample_size / cluster_size)  # enough clusters for ss

# Inefficiency
response <- 2/3                                # proportion contacted included
suitable <- 1/5                                # proportion of suitable clusters
adj_clusters <- ceiling(n_clusters / suitable) # Adjusted number of clusters

# Clusters for Xalapam area 
xalapam_n_clusters <- ceiling( ceiling( 150 / cluster_size ) / suitable )
```




# Administrative limits

The rapid assessment will be performed in some municipalities of the Jalapa department.
Below I show the administrative limits of Jalapa (**Fig. 1**),
the selected municipalities (**Fig. 2**),
and some areas that are to be excluded (**Fig. 3**).
The Xalapam area (shaded with lines in **Fig. 3**) was not included in the
initial rapid assessment due to unwillingness of their leaders to participate,
but will be included in a second rapid assessment stage.


```{r get-limits-data}
# Set included municipalities
included <- c(
  "Jalapa", "San Pedro Pinula", "San Carlos Alzatate", "San Luis Jilotepeque"
)

# Read in limits
municipalities <- readShapePoly(
  fn = "data/shapefiles/borders/municipalities.shp"
)

# Keep only Jalapa
jalapa <- municipalities %>%
  subset(as.character(COD_MUNI) >= 2100 & as.character(COD_MUNI) < 2200)

# Keep only study municipalities
study_munis <- jalapa %>%
  subset(MUNICIPIO %in% included)

# Get top left corner
top_left <-  study_munis %>%
  bbox %>%
  as.data.frame() %>%
  rownames_to_column(var = "direction") %>%
  gather(variable, coordinate, -direction) %>%
  group_by(direction) %>%
  slice(which.max(abs(coordinate))) %>%
  select(direction, coordinate) %>%
  spread(direction, coordinate) %>%
  set_names(toupper(names(.)))

# Read exluded areas
excluded_communities <- "./data/jalapa-excluded-communities.csv" %>%
  # Get the list
  read_csv() %>%
  filter(
    !NUEVO_COD %in% c(2101222, 2101047)
  ) %>%
  # Extend west and north
  bind_rows(
    .,
    top_left,
    mutate(top_left, Y = min(.$Y))
  ) %>%
  # Convert to spatial object
  SpatialPointsDataFrame(
    coords = select(., long = X, lat = Y),
    # coords.nrs = 1:2,
    data = .,
    proj4string = CRS("+init=epsg:4326")
  )

# Get Jalapa "metro" area to exclude it
jalapa_metro <- readShapePoly(
  "./data/shapefiles/community_outlines/Poligonos lugares poblados.shp"
) %>%
  subset(NAME == "JALAPA")

# Set Xalapam area
xalapam <- excluded_communities %>%
  gConvexHull() %>%
  # Intersect with study municipalities
  gIntersection(study_munis)

# Get the convex hull containing the excluded comunities and Jalapa "metro"
excluded_hull <- xalapam %>%
  # Join with Jalapa "metro" area
  gUnion(jalapa_metro)

# Subtract excluded areas
study_area <- gDifference(study_munis, excluded_hull)
```


```{r geo-limits, results='hold', out.width="0.33\\linewidth"}
# Base political limits
plot(jalapa)
title("Fig. 1: Jalapa municipalities")
text(
  coordinates(jalapa),
  labels = gsub(
    pattern = " ",
    replacement = "\n",
    x = iconv(
      x = as.character(jalapa$MUNICIPIO),
      from = "Latin1",
      to = "ASCII//TRANSLIT"
    )
  ),
  cex=0.6
)

# Selected municipalities
plot(jalapa, col = "grey90")
plot(study_munis, col = "white", add = TRUE)
title("Fig. 2: Municipalities included in study")
text(
  coordinates(study_munis),
  labels = gsub(
    pattern = " ",
    replacement = "\n",
    x = iconv(
      x = as.character(study_munis$MUNICIPIO),
      from = "Latin1",
      to = "ASCII//TRANSLIT"
    )
  ),
  cex=0.6
)

# Excluded areas
plot(jalapa, col = "grey90")
plot(study_munis, col = "white", add = TRUE)
plot(jalapa_metro, col = "grey40", add = TRUE)
plot(xalapam, density = 10, angle = 45, add = TRUE)
title("Fig. 3: Excluded areas")
text(
  coordinates(study_munis) - matrix(c(0, -0.02, 0, 0, 0, 0.05, 0, 0), ncol = 2),
  labels = gsub(
    pattern = " ",
    replacement = "\n",
    x = iconv(
      x = as.character(study_munis$MUNICIPIO),
      from = "Latin1",
      to = "ASCII//TRANSLIT"
    )
  ),
  cex=0.6
)
```




# Population density


```{r get-density-data}

# Read in rasters
pop_density <- raster(x = "data/jalapa_density.gri")

# Limit to study area
study_density <- rasterize(study_area, pop_density, mask = TRUE)

# Median cell density
median_density <- median(study_density[], na.rm = TRUE)

# Minimum cluster (area) population for household_size
min_cluster_pop <- household_size * (cluster_size / response)

# Inflate cluster size to ensure enough households
adj_cluster_pop <- min_cluster_pop * 2 / median_density

# Calculate cells per (square) cluster
cluster_side <- ceiling(sqrt(adj_cluster_pop))

# Aggregate population cells
cluster_cells <- aggregate(study_density, fact = cluster_side, fun = sum)

# Percent with enough estimated households
cluster_ecdf <- ecdf(cluster_cells[])
percent_small <- ceiling(cluster_ecdf(cluster_size / response)*100)

# Add Xalapam density
study_density <- rasterize(
  gUnion(study_area, xalapam), pop_density, mask = TRUE
)

# Get cells for Xalapam sampling
xalapam_density <- rasterize(xalapam, pop_density, mask = TRUE)
xalapam_cells <- aggregate(xalapam_density, fact = cluster_side, fun = sum)
```


In **Fig. 4** I show the raw population density from the WorldPop model,
masked by the excluded area (in dark grey).
The Xalapam area is shown outlined in blue.
The highest population densities
(~`r round(max(study_density[], na.rm = TRUE))` persons per household, pph)
are found close to (and inside) the excluded Jalapa "metropolitan" area.
The population density is skewed to lower values
(median ~ `r round(median_density)`, **Fig. 5**),
so we have to carefully define the clusters geographical extent to improve
the probability of selecting clusters with an addequate number of households.


```{r pop-density, results='hold', out.width="0.5\\linewidth"}
# Raw density
dpar <- par()
par(mar = c(2, 2, 3, 1))
plot(study_density)
title("Fig. 4: Raw population density\nand study areas")
plot(jalapa, add = TRUE, asp = 1)
plot(jalapa_metro, add = TRUE, col = "grey20", asp = 1)
lines(study_munis, col = "red")
lines(xalapam, add = TRUE, col = "blue", asp = 1)
par(dpar)

# Raw density
hist(
  study_density, maxpixels = 1e6,
  breaks = seq(0, ceiling(max(study_density[], na.rm = TRUE))),
  xlab = "Count in cells", ylab = "n",
  main = "Fig. 5: Distribution of population density values"
)
```



# Sampling clusters

We want to sample `r cluster_size` households within each cluster, and considering
a `r signif(response*100, 3)`% of response we need to have *at least*
`r ceiling(cluster_size / response)` households,
amounting to `r min_cluster_pop` individuals per cluster.
To define the geographical extent for the clusters I took into account that
50% of the ~100x100m WorldPop cells have a value smaller than `r round(median_density)`,
and adjusted the cluster population[^1] to ~`r ceiling(adj_cluster_pop)` to ensure
that most clusters have at least the number of households we want to sample.

[^1]: Adjusted the needed cluster population to twice the original size,
divided by the median density.

The resulting cluster population requires to aggregate the population density data
to square "cluster sized" cells with `sqrt(adjusted population)` ~ `r cluster_side`
raw cells per side, assuming the median density per cell.
This aggregation results in cells with a resolution of roughly `r signif(res(cluster_cells)[1], 1)`
degrees, or `r cluster_side*100`m,
with at most `r percent_small`% containing less than `r cluster_size / response` households.
I used the total population of each cluster-sized cell as weights[^2] to
randomly select `r adj_clusters` clusters with probability proportional to size, with replacement.
Since the next sampling stage involves randomly picking the same number of 
households within each cluster,
this would ideally allow for every household in the study area to have the
same probability of being selected.


[^2]: Using the value of each cell relative to the maximum value among all cells
as the probability to sample it.



```{r sample-clusters}
# Set seed for reproducibility
set.seed(2017-05)

# Half width
hs <- res(cluster_cells)/2

# Calculate weights
weights <- cluster_cells
weights[is.na(weights[])] <- 0         # set NAs to 0 for sampling
weights <- weights / max(weights[])    # scale to probabilities

# First stage of sampling: sample clusters
sampled_clusters <- sample(
  x = seq_len(length.out = length(weights[])),
  size = adj_clusters,
  replace = TRUE,
  prob = weights[]
)

# Get locations of sample clusters
centers <- xyFromCell(cluster_cells, sampled_clusters)

# Get polygons for each cluster
cluster_cells[is.na(cluster_cells)] <- 0
cluster_polygons <- rasterToPolygons(
  x = cluster_cells
)[unique(sampled_clusters), ]


# Collect data for sample clusters
clusters <- cluster_polygons@data %>%
  rownames_to_column(var = "cell_id") %>%
  mutate(
    correlative = seq(1, n()),
    times = as.vector(table(sampled_clusters)),
    households = layer / household_size
  ) %>%
  select(correlative, cell_id, times, population = layer, households) %>%
  bind_cols(as_tibble(unique(centers))) %>%
  rename(lat = y, long = x)

# Force rownames on cluster data
rownames(clusters) <- clusters$cell_id


# Edit clusters data
cluster_polygons <- SpatialPolygonsDataFrame(
  Sr = cluster_polygons,
  data = clusters,
  match.ID = TRUE
)
```



```{r sample-xalapan-clusters}
# Set seed for reproducibility
set.seed(2017-10)

# Half width
hs <- res(xalapam_cells)/2

# Calculate weights
xalapam_weights <- xalapam_cells
xalapam_weights[is.na(xalapam_weights[])] <- 0     # set NAs to 0 for sampling
xalapam_weights <- xalapam_weights / max(xalapam_weights[]) # scale to probs

# First stage of sampling: sample clusters
sampled_xalapam_clusters <- sample(
  x = seq_len(length.out = length(xalapam_weights[])),
  size = xalapam_n_clusters,
  replace = TRUE,
  prob = xalapam_weights[]
)

# Get locations of sample clusters
xalapam_centers <- xyFromCell(xalapam_cells, sampled_xalapam_clusters)

# Get polygons for each cluster
xalapam_cells[is.na(xalapam_cells)] <- 0
xalapam_polygons <- rasterToPolygons(
  x = xalapam_cells
)[unique(sampled_xalapam_clusters), ]


# Collect data for sample clusters
xalapam_clusters <- xalapam_polygons@data %>%
  rownames_to_column(var = "cell_id") %>%
  mutate(
    correlative = seq(1, n()),
    times = as.vector(table(sampled_xalapam_clusters)),
    households = layer / household_size
  ) %>%
  select(correlative, cell_id, times, population = layer, households) %>%
  bind_cols(as_tibble(unique(xalapam_centers))) %>%
  rename(lat = y, long = x)

# Force rownames on cluster data
rownames(xalapam_clusters) <- xalapam_clusters$cell_id


# Edit clusters data
xalapam_cluster_polygons <- SpatialPolygonsDataFrame(
  Sr = xalapam_polygons,
  data = xalapam_clusters,
  match.ID = TRUE
)
```

A very common approach to spatial sampling uses *geographically balanced sampling*,
which ensures equally-sized areas are represented in the sampling
(usually through some sort of tesselation).
This is very important when there is a strong spatial effect on the dependent
variables or covariates,
but less so when no spatial associations are expected.
The method used to select the clusters in this document *does not* provide a
spatially balanced sample,
but this should not have a big impact on representativity since most of the study
area is so sparesly populated[^3].
In **Fig. 6** I show the aggregated population density and the randomly
selected clusters.
Clusters selected for the Xalapam area are shown in blue.


[^3]: A spatially balanced sample could prove more useful for the second sampling
stage, given that factors at a lower geographical scale
(e.g. point sources of pollution such as factories, sites with regular crop burning,
or areas with heavier motor vehicle trafic) could have a big effect on individual
households.

In **Fig. 8** I include some tiles from satellite imagery provided by Google,
representing selected clusters with low or high estimated number of households.


\newpage
\blandscape

```{r clusters-density, dpi=600, out.width="1\\linewidth", fig.width=9, fig.height=6.5}
dpar <- par()
par(mar = c(2, 2, 3, 1))
aggregate(study_density, fact = cluster_side, fun = sum) %>% plot
title("Fig. 6: Aggregated population density and selected clusters")
plot(jalapa, add = TRUE, asp = 1)
lines(jalapa_metro, col = rgb(0, 0, 1, 0.5), add = TRUE, asp = 1)
lines(xalapam, col = "blue", add = TRUE, asp = 1)
plot(cluster_polygons, add = TRUE, asp = 1)
lines(xalapam_cluster_polygons, add = TRUE, asp = 1, col = "blue")
text(
  coordinates(cluster_polygons),
  labels = cluster_polygons$correlative,
  cex = 0.4, col = "red"
)
text(
  coordinates(xalapam_cluster_polygons),
  labels = xalapam_cluster_polygons$correlative,
  cex = 0.4, col = "blue"
)

par(dpar)
```

\elandscape



```{r write-data, cache=TRUE}
# Write cluster data
clusters %>%
    mutate(
        tipo = "",
        suficientes = "",
        comentario = ""
    ) %>%
  write_csv(path = "output/clusters.csv")


xalapam_cluster_polygons %>%
  as.data.frame %>%
  mutate(
    tipo = "",
    suficientes = "",
    comentario = ""
  ) %>%
  write_csv(path = "output/xalapam_clusters.csv")

# Write cluster polygons
writeSpatialShape(xalapam_cluster_polygons, fn = "output/clusters/xalapam_clusters")

# Function to get cluster tiles
get_tile <- function(cluster, save_path, zoom = 16){
  # file path
  save_path <- file.path(
    save_path,
    stringr::str_pad(
      string = cluster$correlative, width = 2, side = "left", pad = "0"
    )
  )
  
  if(!file.exists(paste0(save_path, ".tif"))){
    # cell center
    center <- cluster[c("lat", "long")] %>% unlist()
    
    # Get tile
    cell <- RgoogleMaps::GetMap(
      center = center[c("lat", "long")], zoom=16, maptype = "satellite"
    )
    
    # Convert to raster
    bb <- cell$BBOX
    cell <- stack(file.path(tempdir(), "mapTile.png"))
    extent(cell) <- extent(bb$ll[,2],bb$ur[,2],bb$ll[,1],bb$ur[,1])
    
    # Save as GTiff
    writeRaster(
      x = cell, filename = save_path, format = "GTiff", overwrite = TRUE
    )
    # Copy the downloaded png
    file.copy(file.path(tempdir(), "mapTile.png"), paste0(save_path, ".png"))
    
  }
  
  cell <- brick(paste0(save_path, ".tif"))
  
  return(cell)
}

# Get all cells
clusters <- clusters %>%
  group_by(correlative, times, population, households, lat, long) %>%
  do(
    cell = get_tile(cluster = ., save_path = "output/cluster_satellite")
  ) %>%
  ungroup()
```


# Cluster evaluation

```{r cluster-suitability, include=FALSE}
# Load visual assessment data
jrivera <- read_csv("data/roofs/cluster_rapid_jrivera.csv")
aramirez <- read_excel("data/roofs/cluster_rapid_aramirez.xlsx")


# Standardize input
st_jrivera <- jrivera %>%
  select(
    correlative, cell_id,
    jr_type = tipo, jr_assesment = suficientes, jr_comment = comentario
  ) %>%
  mutate(
    jr_type = case_when(
      grepl("Rural", jr_type, ignore.case = TRUE) ~ "rural",
      grepl("Urb", jr_type, ignore.case = TRUE) ~ "urban",
      is.na(jr_type) ~ NA_character_,
      TRUE ~ "error"
    )
  )

st_aramirez <- aramirez %>%
  select(
    correlative, cell_id,
    ar_type = tipo, ar_assesment = suficientes, ar_comment = comentario
  ) %>%
  mutate(
    ar_type = case_when(
      grepl("R", ar_type, ignore.case = TRUE) ~ "rural",
      grepl("U", ar_type, ignore.case = TRUE) ~ "urban",
      is.na(ar_type) ~ NA_character_,
      TRUE ~ "error"
    )
  )




#------------------------------------------------------------------------------*
# Review assessment
#------------------------------------------------------------------------------*

# Join assessments
assessment <- st_aramirez %>%
  left_join(st_jrivera)


# Compare assesment

# Evaluated by jrivera
assessment %>% filter(jr_type %in% c("urban", "rural")) %>% nrow()

# Evaluated by aramirez
assessment %>% filter(ar_type %in% c("urban", "rural")) %>% nrow()

# Concordance among evaluated
assessment %>% filter(!is.na(jr_type)) %>% count(ar_type, jr_type)

# Review discordances in cluster type (rural vs urban)
assessment %>%
  filter(
    !is.na(jr_type),
    jr_type != ar_type
  )

# Review discordances in cluster suitability
assessment %>%
  filter(
    !is.na(jr_type),
    jr_assesment != ar_assesment,
    # Remove cluster 60 (cell id 1127)
    correlative != 60
  ) %>%
  select(-ar_comment, -jr_comment)


# Get list of clusters evaluated as suitable
suitable <- assessment %>%
  filter(
    ar_assesment == 1,
    correlative != 57
  )

```


```{r xalapam-cluster-suitability}

# evaluated clusters
xalapam_evaluated <- readxl::read_excel("output/xalapam_clusters.xlsx")

# Select suitable clusters
xalapam_suitable <- st_as_sf(xalapam_cluster_polygons) %>%
  left_join(
    xalapam_evaluated %>%
      mutate(
        correlative = as.integer(correlative),
        cell_id = as.character(cell_id)
      ) %>%
      select(correlative, cell_id, suficientes)
  ) %>%
  filter(suficientes == 1)

# Save suitable clusters
write_sf(xalapam_suitable, "output/clusters/xalapam_suitable.shp")

```




```{r xalapam-rooftops}
# Read roofs data
xalapam_roofs <- readxl::read_excel("data/roofs/Xalapam.xlsx")

# Write for use in qgis
xalapam_roofs %>% write_csv("data/roofs/xalapam_roofs.csv")


#------------------------------------------------------------------------------*
# Sample roofs
#------------------------------------------------------------------------------*

set.seed(2017-10)

selected_roofs <- xalapam_roofs %>%
  select(correlative = Cluster, roof = Id, long = POINT_X, lat = POINT_Y) %>%
  left_join(
    xalapam_suitable %>%
      as.data.frame() %>%
      select(correlative, times)
  ) %>%
  group_by(correlative) %>%
  slice( sample(x = 1:n(), size = first(times) * 20) ) %>%
  mutate(
    id = 1:n()
  ) %>%
  ungroup() %>%
  select(-times)

# Write selected roofs
selected_roofs %>% write_csv("data/roofs/xalapam_sampled_roofs.csv")



#------------------------------------------------------------------------------*
# Plot roofs ----
#------------------------------------------------------------------------------*

plot(xalapam)

xalapam_cluster_polygons %>%
  subset(
    correlative <= 10 &
    correlative %in% xalapam_suitable$correlative
  ) %>%
  lines(col = "blue")

points(xalapam_roofs$POINT_X, xalapam_roofs$POINT_Y, pch = ".", col = "blue")
points(selected_roofs$long, selected_roofs$lat, pch = ".", col = "red")



#------------------------------------------------------------------------------*
# Write gpx files ----
#------------------------------------------------------------------------------*

# Export as individual GPX files for use in the gps receivers
selected_roofs %>%
  mutate(
    correlative = correlative + 200,
    cluster = stringr::str_pad(correlative, width = 3, side = "left", pad = "0"),
    name = stringr::str_pad(id, width = 2, side = "left", pad = "0"),
    name = paste(cluster, name, sep = "-"),
   # Build points
    points = map2(long, lat, ~st_point(c(.x, .y)))
  ) %>%
  st_set_geometry(st_sfc(.$points)) %>%
  st_as_sf() %>%
  split(.$cluster) %>%
  walk(
    ~write_sf(
      obj = select(.x, name, geometry),
      dsn = paste0("output/garmin/xalapam/casas", first(.x$cluster), ".gpx"),
      driver = "GPX",
      delete_dsn = TRUE
    )
  )
  


```


All randomly selected clusters were evaluated by two independent reviewers to
assess if they were suitable for inclusion in the scoping survey.
This was done by looking at recent satellite imagery for each cluster
and estimating the number of structures found in each one by counting the visible roofs.
Clusters were deemed suitable if at least 20 roofs were observed by the reviewer.


```{r suitable-clusters}
suitable_clusters <- clusters %>%
  filter(
    correlative %in% suitable$correlative
  ) %>%
  select(-cell)

selected_clusters <- cluster_polygons %>%
  subset(
    cluster_polygons$correlative %in% suitable_clusters$correlative
  )

suitable_clusters %>%
  mutate_if(
    is.numeric,
    funs(round(., 2))
  ) %>%
  arrange(
    desc(times), correlative
  ) %>%
  select(
    Cluster = correlative,
    "Times sampled" = times,
    "Modeled population" = population,
    "Modeled households" = households,
    Latitude = lat, Longitude = long
  ) %>%
  knitr::kable()
```




# Health services close to selected clusters

```{r nearby-services}
# Read services recorded for Jalapa
services <- read_sf(
  dsn = "data/shapefiles/services/health-services.shp",
  crs = "+init=epsg:4326"
)

# Get data for relevant health related services
health_services <- services %>%
  # Remove services in excluded areas
  st_difference(
    st_as_sf(excluded_hull, crs = "+init=epsg:4326")
  ) %>%
  mutate(
    servicio = tolower(servicio),
    tipo_serv = tolower(tipo_serv),
    service_type = recode_factor(
      tolower(tipo_serv),
      "puesto de salud" = "post",
      "centro convergencia" = "convergence",
      "centro de salud" = "center",
      .default = "other",
      .ordered = TRUE
    )
  ) %>%
  select(
    codgeo, geometry, servicio, tipo_serv, service_type
  ) %>%
  filter(
    service_type != "other"
  ) %>%
  # Add coordinates as regular variables
  bind_cols(
    st_coordinates(.$geometry) %>%
      as_tibble() %>%
      set_names(c("serv_long", "serv_lat"))
  )


# Join services to clusters
nearby_services <- suitable_clusters %>%
  select(correlative, lat, long) %>%
  mutate(join = TRUE) %>%
  left_join(mutate(health_services, join = TRUE)) %>%
  mutate(
    # Distance in meters between cluster centroids and each health service facility
    distance = pointDistance(
      p1 = matrix(c(long, lat), ncol = 2),
      p2 = matrix(c(serv_long, serv_lat), ncol = 2),
      lonlat = TRUE
    )
  ) %>%
  # Keep the 5 facilites closest to each cluster
  arrange(correlative, distance) %>%
  group_by(correlative) %>%
  slice(1) %>%
  ungroup()

# Function to create lines shape from data frame
df_to_line <- function(df){
  lines <- df %>%
    select(long, lat) %>%
    as.matrix() %>%
    Line %>%
    Lines(ID = first(df$cluster))
}

# Lines connecting services to clusters
connect_services <- nearby_services %>%
  select(
    cluster = correlative, servicio, clust_lat = lat, clust_long = long,
    serv_lat, serv_long
  ) %>%
  gather(key = type, value = value, -cluster, -servicio) %>%
  separate(type, into = c("type", "coord"), sep = "_") %>%
  spread(key = coord, value = value) %>%
  split(.$cluster) %>%
  map(df_to_line) %>%
  SpatialLines(proj4string = CRS("+init=epsg:4326"))

# Save data for closest service by cluster
nearby_services %>%
  mutate(
    distance = paste(round(distance/1000, 2), " km")
  ) %>%
  arrange(servicio) %>%
  select(
    cluster = correlative,
    distance,
    service_name = servicio,
    service_code = codgeo,
    service_type,
    service_lat = serv_lat,
    service_long = serv_long
  ) %>%
  write_csv(
    path = "output/nearby-health-services.csv"
  )
```




\newpage
\blandscape

```{r clusters-services, dpi=600, out.width="1\\linewidth", fig.width=10, fig.height=7}
dpar <- par()
par(mar = c(2, 2, 3, 1))
# Base map
plot(jalapa, asp = 1)
title("Fig. 7: Selected clusters and nearby health service facilities")
lines(excluded_hull, col = rgb(0, 0, 1, 0.5), add = TRUE, asp = 1)
# Clusters and lines to services
lines(connect_services, col = "blue")
plot(selected_clusters, add = TRUE, asp = 1, col = "white")
# Label clusters
text(
  coordinates(selected_clusters),
  labels = selected_clusters$correlative,
  cex = 0.4, col = "red"
)
# Unique services
unique_services <- nearby_services %>%
  select(servicio, serv_long, serv_lat) %>%
  unique()
# Label services
raster::text(
  as.matrix(select(unique_services, serv_long, serv_lat)),
  labels = unique_services$servicio,
  cex = 0.4, col = "blue",
  halo = TRUE
)

par(dpar)
```

\elandscape




```{r some-clusters, fig.width=6.5, fig.height=9, out.width="1\\linewidth", cache.rebuild=TRUE, dpi=600}
# Reproducible sampling
set.seed(2017-05)

# panels
panels <- c(4, 3)

# Select tiles
tiles <- clusters %>%
  group_by(households > 100) %>%
  sample_n(ceiling(prod(panels) / 2)) %>%
  ungroup() %>%
  arrange(desc(households)) %>%
  slice(1:prod(panels)) %>%
  rownames_to_column(var = "order") %>%
  mutate(
    cluster = map(
      correlative,
      ~subset(cluster_polygons, cluster_polygons$correlative == .x)
    )
  )

# Set plot parameters
dpar <- par()
par(
  mar = c(1, 1, 1, 1), # panel margins
  mfrow = panels,     # fill 12 panels by row
  oma = c(0, 3, 4, 3)  # outer margin for overall title
)

# Plot each tile
tiles %>%
  split(.$order) %>%
  walk(
    ~{
      plotRGB(x = .x$cell[[1]])
      lines(.x$cluster[[1]], lwd = 2, lty = 2)
      mtext(
        paste0(
          "Cluster ", .x$correlative, ": ",
          floor(.x$households), " households."
        ),
        side = 3, cex = 0.8, padj = 0.9
      )
    }
  )

# Add title
title("Fig. 8: Tiles from selected clusters.", outer=TRUE)
par(dpar)
```




# Extracting and selecting rooftops

Rooftops were manually extracted from selected suitable clusters and the
corresponding satellite images.
Rooftops in excluded areas were removed,
and a sample was collected from the remaining according to requirements for each
cluster.


```{r get-extracted-rooftops}
#------------------------------------------------------------------------------*
# Load roof census data ----
#------------------------------------------------------------------------------*

# List available shapefiles
shapefiles <- "data/roofs/census" %>%
  list.files(full.names = TRUE, pattern = "shp") %>%
  set_names(basename(.))
  

# Get all roofs
all_roofs <- shapefiles %>%
  # Read each file
  map(read_sf) %>%
  # Standardize field names
  map(set_names, nm = c("id", "cluster", "observacio", "geometry")) %>%
  # Identify each point
  map(mutate, rooftop = 1:n()) %>%
  # Standardize CRS
  map(st_set_crs, value = 4326) %>%
  # Record file name
  list(names(.)) %>%
  pmap(~mutate(.x, file = .y)) %>%
  # Bind all
  do.call(rbind, .)


# Clean roof data
clean_roofs <- all_roofs %>%
  # Known fixes
  mutate(
    cluster = case_when(
      cluster %in% c(74, 75) & grepl("jrivera", file) ~ 73,
      TRUE ~ cluster
    )
  ) %>%
  # Exclude duplicates
  filter(
    !duplicated(paste(cluster, rooftop))
  ) %>%
  # Add sampling times
  left_join(
    select(suitable_clusters, cluster = correlative, times)
  ) %>%
  # Keep only suitable clusters
  filter(
    !is.na(times)
  )

# Remove excluded areas
available_roofs <- clean_roofs %>%
  st_difference(st_as_sf(excluded_hull, crs = "4326"))


#------------------------------------------------------------------------------*
# Sample roofs ----
#------------------------------------------------------------------------------*

# Clusters already sampled
sampled_roofs_clusters <- "output/garmin" %>%
  list.files(pattern = ".gpx") %>%
  set_names(.) %>%
  gsub("[^0-9]", "", .) %>%
  as.numeric()

# Reproducible sample
set.seed(2017-06-01)

# Sample parameters
roofs_by_cluster <- 20

# Sample roofs
sampled_roofs <- available_roofs %>%
  # Ignore clusters already sampled
  filter(!cluster %in% sampled_roofs_clusters) %>%
  # By cluster
  split(.$cluster) %>%
  # Sample a subset
  map(
    ~subset(
      .x,
      subset = 1:nrow(.x) %in% sample(
        1:nrow(.x),
        roofs_by_cluster * first(times),
        replace = FALSE
      )
    )
  ) %>%
  # Add house id
  map(
    mutate,
    name = 1:n()
  ) %>%
  # Add left/right pick
  map(
    ~cbind(
      .x,
      elegir = sample(c("izquierda", "derecha"), size = nrow(.x), replace = TRUE)
    )
  ) %>%
  # Bind all
  map(select, id, cluster, observacio, name, elegir, geometry) %>%
  do.call(rbind, .)


# Save roofs if any were selected
if(!is.null(sampled_roofs)){
  # Read previously sampled points
  previous_roofs <- read_sf("data/roofs/sampled/sampled.shp")
  
  # Bind all sampled roofs
  all_sampled_roofs <- previous_roofs %>%
    rbind(sampled_roofs)
  
  # Write sampled roofs
  write_sf(all_sampled_roofs, dsn = "data/roofs/sampled/sampled.shp")
  write_csv(all_sampled_roofs, path = "data/roofs/sampled/casas-elegidas.csv")
  
  # Export as individual GPX files for use in the gps receivers
  all_sampled_roofs %>%
    mutate(
      cluster = stringr::str_pad(cluster, width = 3, side = "left", pad = "0"),
      name = stringr::str_pad(name, width = 2, side = "left", pad = "0"),
      name = paste(cluster, name, sep = "-")
    ) %>%
    split(.$cluster) %>%
    walk(
      ~write_sf(
        obj = select(.x, name, geometry),
        dsn = paste0("output/garmin/casas", first(.x$cluster), ".gpx"),
        driver = "GPX",
        delete_dsn = TRUE
      )
    )
  
  # Record changes in git repo
  repo <- repository(".")
  add(repo, "data/roofs/sampled/casas-elegidas.csv")
  add(repo, "data/roofs/sampled/sampled.*")
  add(repo, "output/garmin/*.gpx")
  commit(repo, message = "Update sampled rooftops")
}
```



